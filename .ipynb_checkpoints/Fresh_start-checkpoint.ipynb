{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer as wnl\n",
    "from nltk.stem.snowball import GermanStemmer as gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = [\"it's\", \"he's\",\"she's\",\"that's\", \"what's\", \"there's\",\\\n",
    "                        \"[newline]\", \"'m\", \"'ve\",\"n't\", \"'ll\",\"'re\", \"won't\", \"'d\", \"'s\"]\n",
    "fixes = [\"it is\", \"he is\",\"she is\",\"that is\", \"what is\", \"there is\",\\\n",
    "                 \" \", \" am\", \" have\", \" not\", \" will\", \" are\", \"will not\", \" would\", \"\"]\n",
    "stop_en = set(stopwords.words('english'))\n",
    "stop_germ = set(stopwords.words('german'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_dic = {}\n",
    "with open('german.dic', 'r', encoding='latin-1') as f:\n",
    "    for row in f:\n",
    "        if len(row) >1:\n",
    "            de_dic[row.strip().lower()] = 1\n",
    "en_dic = {}\n",
    "with open('english.dic', 'r',) as f:\n",
    "    for row in f:\n",
    "        en_dic[row.strip().lower()] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = open('tweets.csv').read()\n",
    "tab_seperated = [item.split('\\t') for item in raw_text.split('\\n') if len(item.split('\\t')) >= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for i in range(len(tab_seperated)):\n",
    "    data[tab_seperated[i][1]] = tab_seperated[i][4]\n",
    "    \n",
    "data_index = data.copy()    \n",
    "for tweet in data_index.keys():\n",
    "    data_index[tweet] = data_index[tweet].lower()\n",
    "    for i in range(len(contractions)):\n",
    "        if contractions[i] in data_index[tweet]:\n",
    "            data_index[tweet] = data_index[tweet].replace(contractions[i], fixes[i])\n",
    "    data_index[tweet] = re.sub('https?[^\\s]+', ' ' , data_index[tweet])\n",
    "    data_index[tweet] = re.sub('[@#][^\\s]+', ' ' , data_index[tweet])\n",
    "    data_index[tweet] = re.sub(r'[0-9][^\\s]+', ' ' , data_index[tweet])\n",
    "    data_index[tweet] = re.sub(r'[^a-zäöüß\\s]', ' ', data_index[tweet])\n",
    "    data_index[tweet] = re.sub(r'[^\\w\\s]', ' ' , data_index[tweet])\n",
    "    \n",
    "terms = {}\n",
    "term_index = {}\n",
    "for num,tweet in data_index.items():\n",
    "    for word in tweet.split():\n",
    "        if word in term_index:\n",
    "            term_index[word].append(num)\n",
    "        elif word not in term_index:\n",
    "            term_index[word] = [num]\n",
    "        if word in terms:\n",
    "            terms[word] += 1\n",
    "        else:\n",
    "            terms[word] = 1\n",
    "\n",
    "for key in term_index.keys():\n",
    "    term_index[key] = sorted(term_index[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_language(term):\n",
    "        de_char = ['ä','ö','ü','ß']\n",
    "        de_score = 0\n",
    "        en_score = 0\n",
    "        for post in term_index[term]:\n",
    "            for i in data_index[post].lower().strip().split():\n",
    "                for char in de_char:\n",
    "                    if char in i:\n",
    "                        de_score +=1\n",
    "                de_score +=1\n",
    "                if i in stop_germ:\n",
    "                    de_score += 1\n",
    "                if i in stop_en:\n",
    "                    en_score += 1\n",
    "        if de_score>en_score:\n",
    "            return 'german'\n",
    "        elif de_score<en_score:\n",
    "            return 'english'\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_freq(dict):\n",
    "        freq = []\n",
    "        for term, val in dict.items():\n",
    "            freq.append((val, term))\n",
    "        freq = sorted(freq)[::-1]\n",
    "        freq_de = []\n",
    "        freq_en = []\n",
    "        for i,j in freq[:200]:\n",
    "            if is_language(j) == 'german':\n",
    "                freq_de.append(j)\n",
    "            else:\n",
    "                freq_en.append(j)\n",
    "        return freq_de, freq_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    " def language(post):\n",
    "        de_char = ['ä','ö','ü','ß']\n",
    "        de_score = 0\n",
    "        en_score = 0\n",
    "        for i in data_index[post].split():\n",
    "            for char in de_char:\n",
    "                    if char in i:\n",
    "                        de_score +=1\n",
    "            if i in stop_germ or i in top_de:\n",
    "                de_score += 1\n",
    "            if i in stop_en or i in top_en:\n",
    "                en_score += 1\n",
    "        if de_score>en_score:\n",
    "            return 'german'\n",
    "        elif en_score>de_score:\n",
    "            return 'english'\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [x for x in terms.keys()][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "für\n",
      "überprüft\n",
      "erklärbare\n",
      "können\n",
      "glückwunsch\n",
      "eingeschläfert\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    en_lemma = {}\n",
    "    tags = ['n','v','a','s','r']\n",
    "    for tag in tags:\n",
    "        for lemma in (wnl.lemmatize(wnl,word=i, pos=tag)):\n",
    "            en_lemma[lemma] = 1 \n",
    "    for j in en_lemma:\n",
    "        if (j not in en_dic) and (j not in de_dic):\n",
    "            print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_misspells():\n",
    "        words =sorted([key for key in terms.keys()])\n",
    "        de = []\n",
    "        en = []\n",
    "        for term in words[:200]:\n",
    "            g_count = 0\n",
    "            e_count = 0\n",
    "            e_posts = []\n",
    "            g_posts = []\n",
    "            \n",
    "            #pos tags for lemmatization generation\n",
    "            tags = ['n','v','a','s','r']\n",
    "            en_lemma = {}\n",
    "            for tag in tags:\n",
    "                for lemma in (wnl.lemmatize(wnl,word=term, pos=tag)):\n",
    "                    en_lemma[lemma] = 1 \n",
    "                    \n",
    "            #German lemmatiziaton/stemming\n",
    "            de_lemma = term\n",
    "            \n",
    "            for post in term_index[term]:\n",
    "                if language(post) == 'german':\n",
    "                    ## get german misspelling count\n",
    "                    if de_lemma not in de_dic:    \n",
    "                        g_count += 1\n",
    "                        g_posts.append(post)\n",
    "                        \n",
    "                elif language(post) == 'english':\n",
    "\n",
    "                    ## get german misspelling count\n",
    "                    if len([i for i in en_lemma.keys() if i in en_dic]) == 0:\n",
    "                        e_count += 1\n",
    "                        e_posts.append(post)\n",
    "                        \n",
    "                else:\n",
    "                    lang = is_language(term)\n",
    "                    if lang ==  None:\n",
    "                        continue\n",
    "\n",
    "                    if lang == 'german':\n",
    "                        \n",
    "                        ## get german misspelling count    \n",
    "                        if de_lemma not in de_dic:\n",
    "\n",
    "                            g_count += 1\n",
    "                            g_posts.append(post)\n",
    "                    else:\n",
    "                        ## get english misspelling count\n",
    "                        if len([i for i in en_lemma.keys() if i in en_dic]) == 0:\n",
    "                            e_count += 1\n",
    "                            e_posts.append(post)\n",
    "                            \n",
    "            if g_count > 0:\n",
    "                de.append((g_count, term, g_posts))\n",
    "            if e_count > 0:\n",
    "                en.append((e_count, term, e_posts))\n",
    "        return sorted(de)[::-1], sorted(en)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_mis, en_mis = get_misspells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(de_mis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#             term = ''\n",
    "#             for i in range(len(x)):\n",
    "#                 try:\n",
    "#                     if x[i] != [i+2]:\n",
    "#                         term += x[i]\n",
    "#                 except:\n",
    "#                     term += x[i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
